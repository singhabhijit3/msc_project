baseline_1_results: num_steps=20, batch_size=20, hidden_size=200, 1 LSTM, no dropout, ADAM, (E9-5.128)
zaremba_results: num_steps=20, batch_size=20, hidden_size=200, 2 LSTM, no dropout, ADAM, (E8-5.159)

baseline_1_results_2: num_steps=35, batch_size=20, hidden_size=650, 1 LSTM, no dropout, ADAM, (E6-4.983)
zaremba_results_2: num_steps=35, batch_size=20, hidden_size=650, 2 LSTM, no dropout, ADAM, (E6-5.065)

zaremba_results_3: num_steps=35, batch_size=20, hidden_size=650, 2 LSTM, 3 dropout layers (0.5), ADAM, (E15-4.951)

From here it uses early stopping:

zaremba_results_4: num_steps=35, batch_size=20, hidden_size=650, 2 LSTM, 3 dropout layers (0.5), ADAM, (E17-4.954)

zaremba_results_5: num_steps=35, batch_size=20, hidden_size=650, 2 LSTM, 2 dropout layers (0.5), ADAM, (E11-4.899)

zaremba_results_6: num_steps=35, batch_size=20, hidden_size=650, 2 LSTM, 1 dropout layer (0.5), ADAM, (E8-4.968)

baseline_1_results_3: num_steps=35, batch_size=20, hidden_size=650, 1 LSTM, no dropout, ADAM(lr=0.01), (Ex-x.xxx)
zaremba_results_7: num_steps=35, batch_size=20, hidden_size=650, 2 LSTM, 2 dropout layers (0.5), ADAM(lr=0.01), (Ex-x.xxx)




